[{"id":"b669a935.fe49c8","type":"change","z":"f8643374.8836d8","name":"Extract image URL","rules":[{"t":"set","p":"payload","pt":"msg","to":"payload.imageurl","tot":"msg"}],"action":"","property":"","from":"","to":"","reg":false,"x":287.5,"y":264,"wires":[["2e324b0.3279eb6"]]},{"id":"618b421f.f7735c","type":"switch","z":"f8643374.8836d8","name":"Check image url","property":"payload.imageurl","propertyType":"msg","rules":[{"t":"null"},{"t":"else"}],"checkall":"true","outputs":2,"x":317.5,"y":104,"wires":[["51524de9.58a62c"],["b669a935.fe49c8"]]},{"id":"702ae9e.b9b7718","type":"http in","z":"f8643374.8836d8","name":"","url":"/people","method":"get","swaggerDoc":"","x":127.5,"y":104,"wires":[["618b421f.f7735c"]]},{"id":"b4ff21f8.1baa8","type":"template","z":"f8643374.8836d8","name":"Report faces via HTML template","field":"payload","fieldType":"msg","format":"handlebars","syntax":"mustache","template":"<h1>Visual Recognition - Results </h1>\n    <p>Analyzed image: {{result.images.0.resolved_url}}<br/><img id=\"image\" src=\"{{result.images.0.resolved_url}}\" height=\"200\"/></p>\n    {{^result}}\n        <P>No Face detected</P>\n    {{/result}}\n    <p>Images Processed: {{result.images_processed}}</p>\n        {{#result.images.0.faces}}\n            <tr>\n            <p>Age Range:  {{age.min}} - {{age.max}}</p>\n            <p>Gender:  {{gender.gender}}</p>\n            <p>Name:  {{identity.name}}</p>\n            <p id=\"product\"></p>\n            <p1 id=\"so\"></p1>\n            <p2 id=\"so2\"></p2>\n        <script>\n            var card_type,loan_type,a=({{age.max}}+{{age.min}})/2;\nvar img1 = document.createElement(\"img1\");\nvar img2 = document.createElement(\"img2\");\n\n\n                    if(a<18){img1.src = \"https://s-media-cache-ak0.pinimg.com/736x/d6/27/ed/d627ede5fbbb4864d85b9897b759782d.jpg\";loan_type=\"general_investing\";card_type=\"prepaid\";}\n                    else if(a<25){img1.src = \"http://www.lifeflicker.com/wp-content/uploads/2016/09/Paying-Off-Student-Loans-360x240.jpg\";loan_type=\"student\"; card_type=\"student\";}\n                    else if(a<35){img1.src = \"https://i.ytimg.com/vi/zsqx_4ck7YY/maxresdefault.jpg\";img2.src = \"http://mxradvogados.com.br/wp-content/uploads/2016/07/vendaimovel.jpeg\";loan_type=\"car/home\";card_type=\"visa/amex/master_card\";}\n                    else{img1.src = \"https://i.ytimg.com/vi/zsqx_4ck7YY/maxresdefault.jpg\";img2.src = \"http://mxradvogados.com.br/wp-content/uploads/2016/07/vendaimovel.jpeg\";loan_type=\"deposit\";card_type=\"visa/amex/master_card\";}\n                \n        document.getElementById(\"product\").innerHTML=\"Products offer:  We suggest a \"+loan_type+\" loan and a \"+card_type+\" card!\";\n        var src = document.getElementById(\"so\");\n        var src2 = document.getElementById(\"so2\");\n\nsrc.appendChild(img1);\nsrc2.appendChild(img2);\n\n               </script>\n            </p>\n        </tr>{{/result.images.0.faces}}\n    <form  action=\"{{req._parsedUrl.pathname}}\">\n        <br><input type=\"submit\" value=\"Try again or go back to the home page\"/>\n    </form>","x":627.5,"y":197,"wires":[["bddedb29.271218"]]},{"id":"bddedb29.271218","type":"http response","z":"f8643374.8836d8","name":"","x":927.5,"y":104,"wires":[]},{"id":"2e324b0.3279eb6","type":"visual-recognition-v3","z":"f8643374.8836d8","name":"","apikey":"","image-feature":"detectFaces","x":297.5,"y":404,"wires":[["bc3e2180.eb3158","f1dce13f.88b78","e26207fc.eb3f98","b4ff21f8.1baa8"]]},{"id":"bc3e2180.eb3158","type":"debug","z":"f8643374.8836d8","name":"Print msg.result.images","active":true,"console":"false","complete":"result.images","x":607.5,"y":504,"wires":[]},{"id":"f1dce13f.88b78","type":"template","z":"f8643374.8836d8","name":"Print result via a template","field":"payload","fieldType":"msg","format":"handlebars","syntax":"mustache","template":"// Template functions can access the json array via this .0. notation.\n// See the Watson Visual Recognition v3 API Documentation at\n// https://watson-api-explorer.mybluemix.net/apis/visual-recognition-v3#!/visual-recognition/get_v3_detect_faces\n\nFirst face in result is a {{result.images.0.faces.0.gender.gender}} !","x":607.5,"y":304,"wires":[["73eda2ad.fb1014"]]},{"id":"73eda2ad.fb1014","type":"debug","z":"f8643374.8836d8","name":"","active":true,"console":"false","complete":"payload","x":947.5,"y":304,"wires":[]},{"id":"e26207fc.eb3f98","type":"function","z":"f8643374.8836d8","name":"Is this a Celebrity","func":"// A function to determine if this image contains a celebrity.\n// Functions can access the msg.result via array indexes\n// Watson Visual Recognition v3 API Documentation is post here:\n// https://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/visual-recognition/api/v3/?node#detect_faces\nvar i=0;\nvar Celebrity=0;\nvar CelebrityName=\"No one famous detected\";\n\n// There might be multiple faces in this image.\n// Loop through the faces and determine if Watson has\n// detected the identity of at least one celebrity.\nwhile ( msg.result.images[0].faces[i] ) {\n    if (msg.result.images[0].faces[i].identity != null) {\n        Celebrity=1;\n        CelebrityName=msg.result.images[0].faces[i].identity.name;\n    }\n    i++;\n}\n\nmsg.payload = CelebrityName;\n// if a Celebrity was found, send the Name to output 1\n// else send the default \"No one famous detected\" to output 2\nif (Celebrity == 1) {\n        return [ msg, null ];\n} else {\n    return [ null, msg ];\n}\n","outputs":"2","noerr":0,"x":587.5,"y":404,"wires":[["455fdcae.28f1d4"],["26bffc7d.619d44"]]},{"id":"26bffc7d.619d44","type":"debug","z":"f8643374.8836d8","name":"","active":true,"console":"false","complete":"payload","x":947.5,"y":424,"wires":[]},{"id":"455fdcae.28f1d4","type":"template","z":"f8643374.8836d8","name":"Paparazzi","field":"payload","fieldType":"msg","format":"handlebars","syntax":"mustache","template":"This image contains a celebrity: {{payload}} !","x":787.5,"y":364,"wires":[["26bffc7d.619d44"]]},{"id":"5ce2d7ec.500ba","type":"comment","z":"f8643374.8836d8","name":"Step #1 - Create a Visual Recognition Service","info":"1. Log into your Bluemix account\n2. Navigate to the Bluemix Catalog\n3. Scroll to the Watson Services section\n4. Find and click on the Visual Recognition service\n5. Create an unbounded Visual Recognition instance\n6. Open the new service and navigate to the Service Credentials\n7. Copy the api_key to the clipboard\n8. Open the above \"visual recognition v3\" node and paste your new API Key","x":247.5,"y":464,"wires":[]},{"id":"51524de9.58a62c","type":"template","z":"f8643374.8836d8","name":"Home_Page","field":"payload","fieldType":"msg","format":"handlebars","syntax":"mustache","template":"<h1>Visual Recognition </h1>\n<H2>Give us a picture of a person and we will propose you the best bank offers applied on them</H2>\n<img height=\"42\" width=\"42\" src=\"https://www.ibm.com/blogs/bluemix/wp-content/uploads/2016/10/WatsonVisualRecognition.png\">\n<form  action=\"{{req._parsedUrl.pathname}}\">\n    <br>Image URL: <input type=\"text\" name=\"imageurl\"/>\n    <input type=\"submit\" value=\"Analyze\"/>\n</form>","x":627.5,"y":100,"wires":[["bddedb29.271218"]]}]